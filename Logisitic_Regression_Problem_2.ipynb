{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logisitic_Regression_Problem_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepak-ucfknight/Machine_Learning_Spring19/blob/master/Logisitic_Regression_Problem_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UJbKTHeKyLxq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "Machine Learning Assignment  - 1 \n",
        "\n",
        "Deepak - 4736979"
      ]
    },
    {
      "metadata": {
        "id": "nEt2bhuFyZ-X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# importing datasets from keras\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mzcG_p-2ysW8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setting Variables"
      ]
    },
    {
      "metadata": {
        "id": "fRnQjafEyu3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 1\n",
        "epochs = 12\n",
        "classifier_digit = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WJ2BOZhUy5IA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Image Dimensions"
      ]
    },
    {
      "metadata": {
        "id": "9t13LD74y9dE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rows = 28\n",
        "cols = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rpq1Vt8dzC-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading MNIST Datasets"
      ]
    },
    {
      "metadata": {
        "id": "GQ52cYldzI7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5_RirSQzUCP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reshaping the Data  based on the backend format,  i.e. channels first or channels last"
      ]
    },
    {
      "metadata": {
        "id": "rY_jLwRwzcMF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, rows, cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, rows, cols)\n",
        "    input_shape = (1, rows, cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
        "    input_shape = (rows, cols, 1)\n",
        "    \n",
        "x_train = x_train / 255;\n",
        "x_test = x_test / 255;\n",
        "sigmoid_y_train = y_train\n",
        "sigmoid_y_test = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmImRPQ0z8xF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def modify_labels(y):\n",
        "  y = np.array(y)\n",
        "  return np.where(y == classifier_digit, 1, 0)\n",
        "  \n",
        "\n",
        "sigmoid_y_train = modify_labels(y_train)\n",
        "sigmoid_y_test = modify_labels(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KK456aPm7ia8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], -1).T\n",
        "x_test = x_test.reshape(x_test.shape[0], -1).T\n",
        "y_train = sigmoid_y_train.T\n",
        "y_test = sigmoid_y_test.T\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLrg5emf8csF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Activation Function : Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "68KTbx7r8qUC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "   return 1.0/(1.0+np.exp(-z))\n",
        "  \n",
        "def sigmoid_prime(z):\n",
        "  return sigmoid(z)*(1-sigmoid(z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sgov1DX59shs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "tEYMTMd79yDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This function initializes the weights matrices and bias to zero\n",
        "\n",
        "def initialize_with_zeros(dim):\n",
        "   w = np.zeros(shape=(dim, num_classes))\n",
        "   b = 0\n",
        "   return w,b\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dZL1hzqlgflB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mini_batches(X, Y, batchsize):\n",
        "    for start_idx in range(0, X.shape[0] - batchsize + 1, batchsize):\n",
        "        excerpt = slice(start_idx, start_idx + batchsize)\n",
        "        yield X[excerpt], Y[excerpt]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vy4bPOUD-UNW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def binary_entropy(w,b,X,Y):\n",
        "  \n",
        "  m =  m = X.shape[1]\n",
        "  A = sigmoid(np.dot(w.T, X) + b)\n",
        "  cost = (- 1 / m) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A))) # binary entropy\n",
        " \n",
        "  # binary entropy gradients\n",
        "  dw = (1 / m) * np.dot(X, (A - Y).T)\n",
        "  db = (1 / m) * np.sum(A - Y)\n",
        "  \n",
        "  grads = {\"dw\": dw,\n",
        "            \"db\": db }\n",
        "  \n",
        "  cost = np.squeeze(cost)\n",
        "    \n",
        "  return grads, cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UJPa4A-N_pg6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# gradient calculation has to be updated - under construction\n",
        "def squared_loss(w,b,X,Y):\n",
        "  \n",
        "  m =  m = X.shape[1]\n",
        "  A = sigmoid(np.dot(w.T, X) + b)\n",
        "  cost = np.square(Y - A).mean()\n",
        " \n",
        "  # binary entropy gradients\n",
        "  dw = (1 / m) * np.dot(X, (A - Y).T)\n",
        "  db = (1 / m) * np.sum(A - Y)\n",
        "  \n",
        "  grads = {\"dw\": dw,\n",
        "            \"db\": db }\n",
        "    \n",
        "  return grads, cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "okmr8kUUDkyE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Back Propogation of Gradient Descent"
      ]
    },
    {
      "metadata": {
        "id": "Y97fwUXNDo2m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def optimize(w, b, X, Y, epochs, learning_rate, print_cost = False):\n",
        "  \n",
        "  costs = []\n",
        "    \n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  for i in range(epochs):\n",
        "      \n",
        "    for batch in mini_batches(X.T, Y.T, batch_size):\n",
        "    \n",
        "       x_batch, y_batch = batch\n",
        "       grads, cost = binary_entropy(w, b, x_batch.T, y_batch.T)\n",
        "       dw = grads[\"dw\"]\n",
        "       db = grads[\"db\"]\n",
        "       w = w - learning_rate * dw \n",
        "       b = b - learning_rate * db\n",
        "\n",
        "       \n",
        "    costs.append(cost)\n",
        "\n",
        "    if print_cost:\n",
        "       print (\"Loss after iteration %i: %f\" % (i, cost))\n",
        "            \n",
        "  params = {\"w\": w,\n",
        "            \"b\": b}\n",
        "\n",
        "  grads = {\"dw\": dw,\n",
        "               \"db\": db}\n",
        "\n",
        "  return params, grads, costs\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rC7hPQ8lEy2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predicting Values"
      ]
    },
    {
      "metadata": {
        "id": "Hy_bA1lcE1h0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(w, b, X):\n",
        "   m = X.shape[1]\n",
        "   Y_prediction = np.zeros((1, m))\n",
        "   w = w.reshape(X.shape[0], num_classes)\n",
        "   A = sigmoid(np.dot(w.T, X) + b)\n",
        "  \n",
        "   for i in range(A.shape[1]):\n",
        "      Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
        "   return Y_prediction\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O-HNoXKRF_zQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model"
      ]
    },
    {
      "metadata": {
        "id": "g8g8nc_SGA94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
        "   w, b = initialize_with_zeros(X_train.shape[0])\n",
        "   parameters, grads, costs = optimize(w, b, X_train, Y_train, num_iterations, learning_rate, print_cost)\n",
        "   w = parameters[\"w\"]\n",
        "   b = parameters[\"b\"]\n",
        "   Y_prediction_test = predict(w, b, X_test)\n",
        "   Y_prediction_train = predict(w, b, X_train)\n",
        "  \n",
        "   print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
        "   print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
        "\n",
        "    \n",
        "   d = { \"costs\": costs,\n",
        "          \"Y_prediction_test\": Y_prediction_test, \n",
        "          \"Y_prediction_train\" : Y_prediction_train, \n",
        "          \"w\" : w, \n",
        "          \"b\" : b,\n",
        "          \"learning_rate\" : learning_rate,\n",
        "          \"num_iterations\": num_iterations }\n",
        "    \n",
        "   return d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-tjR-3iGoTz",
        "colab_type": "code",
        "outputId": "8ffca4be-036c-4352-8e4e-de30902840d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = model(x_train, sigmoid_y_train, x_test, sigmoid_y_test, num_iterations = 12, learning_rate = 0.001, print_cost = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(784, 60000)\n",
            "(60000,)\n",
            "Loss after iteration 0: 0.229671\n",
            "Loss after iteration 1: 0.192281\n",
            "Loss after iteration 2: 0.168393\n",
            "Loss after iteration 3: 0.151834\n",
            "Loss after iteration 4: 0.139640\n",
            "Loss after iteration 5: 0.130228\n",
            "Loss after iteration 6: 0.122692\n",
            "Loss after iteration 7: 0.116485\n",
            "Loss after iteration 8: 0.111255\n",
            "Loss after iteration 9: 0.106766\n",
            "Loss after iteration 10: 0.102857\n",
            "Loss after iteration 11: 0.099411\n",
            "train accuracy: 94.97833333333334 %\n",
            "test accuracy: 95.23 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cfRJiJYG9r8A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Keras Implementation\n"
      ]
    },
    {
      "metadata": {
        "id": "E2jir-by9tyA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xth9UsrkD75r",
        "colab_type": "code",
        "outputId": "e90d00a7-000f-464f-81de-2a2c8382b8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "keras_x_train = x_train.T\n",
        "keras_y_train = y_train\n",
        "keras_x_test = x_test.T\n",
        "keras_y_test = y_test\n",
        "\n",
        "keras_y_train = keras.utils.to_categorical(keras_y_train, 10)\n",
        "keras_y_test = keras.utils.to_categorical(keras_y_test, 10)\n",
        "\n",
        "\n",
        "print(keras_y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oFWdace6-C7U",
        "colab_type": "code",
        "outputId": "a87af435-77be-478b-bf03-04899f3e4ce0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "print(keras_x_train.shape)\n",
        "print(keras_x_test.shape)\n",
        "print(keras_y_train.shape)\n",
        "print(keras_y_test.shape)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='softmax', input_dim=784))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 10)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-OSTQbneAtaI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "guPkzEmwA_My",
        "colab_type": "code",
        "outputId": "d8aa237e-04c9-4e6c-b9bc-c4714dcb6b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "model.fit(keras_x_train, keras_y_train, nb_epoch=12, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.2007 - acc: 0.9376\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1265 - acc: 0.9589\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1163 - acc: 0.9629\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1110 - acc: 0.9650\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1077 - acc: 0.9667\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1052 - acc: 0.9674\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1033 - acc: 0.9683\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1019 - acc: 0.9688\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1006 - acc: 0.9690\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0995 - acc: 0.9696\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0986 - acc: 0.9700\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.0979 - acc: 0.9705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb2ef94e320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "QQVCehyzBVTN",
        "colab_type": "code",
        "outputId": "8890a91b-61eb-438f-bfe2-f2f9e242a3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "score = model.evaluate(x_test.T, keras_y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.09107155102714896\n",
            "Test accuracy: 0.9731\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}